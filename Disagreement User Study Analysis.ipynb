{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Packages Used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load data into numpy array and pandas dataframes:**\n",
    "* **datasetXX_nTreeRanks:** Ordered n-ary tree ranks for dataset XX (A, B, C, or D)\n",
    "* **datasetXX_absRanks:** Ordered absolute post-traversal ranks for dataset XX (A, B, C, or D)\n",
    "* **TODO:** At some point, update with Regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawData = np.loadtxt(fname='disagreement-mturk-raw-ids-rankings-only.csv', delimiter=',', skiprows=1, \n",
    "                     dtype=np.dtype([('version', 'i4'), ('responseId', 'S25'), \n",
    "                                     ('rDA_1', 'f4'), ('rDA_2', 'f4'), ('rDA_3', 'f4'), ('rDA_4', 'f4'), ('rDA_5', 'f4'), \n",
    "                                     ('sDA_1', 'f4'), ('sDA_2', 'f4'), ('sDA_3', 'f4'), ('sDA_4', 'f4'), ('sDA_5', 'f4'), \n",
    "                                     ('rDB_1', 'f4'), ('rDB_2', 'f4'), ('rDB_3', 'f4'), ('rDB_4', 'f4'), ('rDB_5', 'f4'), \n",
    "                                     ('sDB_1', 'f4'), ('sDB_2', 'f4'), ('sDB_3', 'f4'), ('sDB_4', 'f4'), ('sDB_5', 'f4'), \n",
    "                                     ('rDC_1', 'f4'), ('rDC_2', 'f4'), ('rDC_3', 'f4'), ('rDC_4', 'f4'), ('rDC_5', 'f4'), \n",
    "                                     ('sDC_1', 'f4'), ('sDC_2', 'f4'), ('sDC_3', 'f4'), ('sDC_4', 'f4'), ('sDC_5', 'f4'), \n",
    "                                     ('rDD_1', 'f4'), ('rDD_2', 'f4'), ('rDD_3', 'f4'), ('rDD_4', 'f4'), ('rDD_5', 'f4'), \n",
    "                                     ('sDD_1', 'f4'), ('sDD_2', 'f4'), ('sDD_3', 'f4'), ('sDD_4', 'f4'), ('sDD_5', 'f4'), \n",
    "                                     ('mTurkCode', 'S25')]))\n",
    "\n",
    "# initialize n-ary tree ranking results with headers\n",
    "nTresults = [['datasetId', 'overall_convertedR', 'overall_confidenceLowerBound', 'overall_confidenceUpperBound',\n",
    "             'group1_convertedR', 'group1_confidenceLowerBound', 'group1_confidenceUpperBound',\n",
    "             'group2_convertedR', 'group2_confidenceLowerBound', 'group2_confidenceUpperBound']]\n",
    "\n",
    "# full data frame\n",
    "df = pd.DataFrame(rawData)\n",
    "\n",
    "# Utils for statistics and all datasets, defining 'ground truth' columns in dataframes\n",
    "overallDropCols = [50,51]\n",
    "groupDropCols = [25, 26]\n",
    "NtId = 50\n",
    "\n",
    "\n",
    "# Ground Truth Ranking Datasets\n",
    "datasetA_nTreeRanks = df.ix[df['version']==3].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_absRanks = df.ix[df['version']==4].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset A\n",
    "datasetA_overall_ranks = df.filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "\n",
    "datasetA_overall_sliders = df.filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T\n",
    "datasetA_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T\n",
    "datasetA_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset B\n",
    "datasetB_overall_ranks = df.filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "datasetB_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "datasetB_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "\n",
    "datasetB_overall_sliders = df.filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T\n",
    "datasetB_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T\n",
    "datasetB_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset C\n",
    "datasetC_overall_ranks = df.filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "datasetC_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "datasetC_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "\n",
    "datasetC_overall_sliders = df.filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T\n",
    "datasetC_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T\n",
    "datasetC_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset D\n",
    "datasetD_overall_ranks = df.filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "datasetD_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "datasetD_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "\n",
    "datasetD_overall_sliders = df.filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T\n",
    "datasetD_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T\n",
    "datasetD_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher Transformation\n",
    "* Background and Formula: https://en.wikipedia.org/wiki/Fisher_transformation\n",
    "* Implementation References: \n",
    "    1. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.925.428&rep=rep1&type=pdf\n",
    "    2. http://dept.stat.lsa.umich.edu/~kshedden/Python-Workshop/stats_calculations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fisherTransform(corr):\n",
    "    '''Given 1-row matrix of correlation coefficients, computes Fisher Transform matrix of same dimensions'''\n",
    "    \n",
    "    # Treat correlation of 1 as 0.9999 to prevent undefined values\n",
    "    adjustedCorr = corr.applymap(lambda x: 0.9999 if (x == 1.0) else x)\n",
    "    adjustedCorr = corr.applymap(lambda x: -0.9999 if (x == -1.0) else x)\n",
    "    \n",
    "    # Fisher transform all the correlation coefficients (equivalent to hyperbolic tangent)\n",
    "    F = np.arctanh(adjustedCorr)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgFisherTransform(F):\n",
    "    '''Given 1-row Matrix of Fisher Transform Values, returns Average Fisher Transform'''\n",
    "    return F.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisherStdErr(n):\n",
    "    '''Given sample size n, returns standard error for Fisher Transform'''\n",
    "    return (1/np.sqrt(n-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confidenceInterval(refP, critZ, stdErr):\n",
    "    '''\n",
    "    Given a reference point (generally mean of dataset) and standard error value, returns confidence interval\n",
    "    low = refP - (critZ * stdErr)\n",
    "    high = refP + (critZ * stdErr)\n",
    "    '''\n",
    "    low = refP - (critZ * stdErr)\n",
    "    high = refP + (critZ * stdErr)\n",
    "    \n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertZtoR(zVal):\n",
    "    '''Given Fisher Transform z val, computes r Correlation Coefficient'''\n",
    "    return np.tanh(zVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculate Correlations and Store Results:**\n",
    "* TODO: Currently only applying n-ary tree ranking, but data is in place for absolute ranking also (indices for n-ary tree are hard-coded currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeStats(df, dropCols, gtId, statsMethod):\n",
    "    '''Helper function for buildStats. Given dataframe, indices for columns to drop, and \n",
    "    index for the ground truth ranking id, and stats method, it returns tuple of coefficients'''\n",
    "\n",
    "    # all correlations\n",
    "    corr = df.corr(method=statsMethod, min_periods=5)\n",
    "    # correlations with n-ary tree ranking\n",
    "    #TODO: these indices might need to be updated if we add absolute ranking\n",
    "    nTOverall = corr[-2:-1].drop(corr.columns[dropCols],axis=1)\n",
    "    # average n-ary tree correlation\n",
    "    avgNtOverall = nTOverall.mean(axis=1)\n",
    "    avgR = avgNtOverall[gtId]\n",
    "    \n",
    "    # average F-transform of n-ary tree metric\n",
    "    fTransform = fisherTransform(nTOverall)\n",
    "    avgFvec = avgFisherTransform(fTransform)\n",
    "    avgF = avgFvec[gtId]\n",
    "    \n",
    "    # sample size (n is number of columns, which is sample size)\n",
    "    m, n = corr.shape\n",
    "    \n",
    "    # stdErr on fisher transform\n",
    "    fStdErr = fisherStdErr(n)\n",
    "    \n",
    "    # use Z criterion of 1.96 for 95% confidence interval\n",
    "    critZ = 1.96\n",
    "    \n",
    "    # confidence interval\n",
    "    fLow, fHigh = confidenceInterval(avgF, critZ, fStdErr)\n",
    "    rLow = convertZtoR(fLow),\n",
    "    rHigh = convertZtoR(fHigh)\n",
    "    \n",
    "    # converted (transformed) average correlation coeff\n",
    "    convAvgRvec = convertZtoR(avgFvec)\n",
    "    convR = convAvgRvec[gtId]\n",
    "    \n",
    "    return convR, rLow, rHigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStats(dataId, overall, group1, group2, statsMethod):\n",
    "    '''Given a dataset label, overall data set and dataset for each group, returns list of results for pearson method'''\n",
    "    \n",
    "    #initialize empty list of stats\n",
    "    stats=[dataId]\n",
    "    \n",
    "    # overall data\n",
    "    overallR, overallF, overallConvR = computeStats(overall, overallDropCols, NtId, statsMethod)\n",
    "    stats.append(overallR)\n",
    "    stats.append(overallF)\n",
    "    stats.append(overallConvR)\n",
    "    \n",
    "    # group 1 data\n",
    "    group1R, group1F, group1ConvR = computeStats(group1, groupDropCols, NtId, statsMethod)\n",
    "    stats.append(group1R)\n",
    "    stats.append(group1F)\n",
    "    stats.append(group1ConvR)\n",
    "    \n",
    "    # group 2 data\n",
    "    group2R, group2F, group2ConvR = computeStats(group2, groupDropCols, NtId, statsMethod)\n",
    "    stats.append(group2R)\n",
    "    stats.append(group2F)\n",
    "    stats.append(group2ConvR)\n",
    "    \n",
    "    \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    }
   ],
   "source": [
    "# Dataset A Stats\n",
    "\n",
    "# Dataset A Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetA_ranks_pearson', datasetA_overall_ranks, \n",
    "                           datasetA_group1_ranks, datasetA_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetA_ranks_spearman', datasetA_overall_ranks, \n",
    "                           datasetA_group1_ranks, datasetA_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset A Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetA_sliders_pearson', datasetA_overall_sliders, \n",
    "                           datasetA_group1_sliders, datasetA_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetA_sliders_spearman', datasetA_overall_sliders, \n",
    "                           datasetA_group1_sliders, datasetA_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset B Stats\n",
    "\n",
    "# Dataset B Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetB_ranks_pearson', datasetB_overall_ranks, \n",
    "                           datasetB_group1_ranks, datasetB_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetB_ranks_spearman', datasetB_overall_ranks, \n",
    "                           datasetB_group1_ranks, datasetB_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset B Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetB_sliders_pearson', datasetB_overall_sliders, \n",
    "                           datasetB_group1_sliders, datasetB_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetB_sliders_spearman', datasetB_overall_sliders, \n",
    "                           datasetB_group1_sliders, datasetB_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset C Stats\n",
    "\n",
    "# Dataset C Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetC_ranks_pearson', datasetC_overall_ranks, \n",
    "                           datasetC_group1_ranks, datasetC_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetC_ranks_spearman', datasetC_overall_ranks, \n",
    "                           datasetC_group1_ranks, datasetC_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset C Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetC_sliders_pearson', datasetC_overall_sliders, \n",
    "                           datasetC_group1_sliders, datasetC_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetC_sliders_spearman', datasetC_overall_sliders, \n",
    "                           datasetC_group1_sliders, datasetC_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset D Stats\n",
    "\n",
    "# Dataset D Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetD_ranks_pearson', datasetD_overall_ranks, \n",
    "                           datasetD_group1_ranks, datasetD_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetD_ranks_spearman', datasetD_overall_ranks, \n",
    "                           datasetD_group1_ranks, datasetD_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset D Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetD_sliders_pearson', datasetD_overall_sliders, \n",
    "                           datasetD_group1_sliders, datasetD_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetD_sliders_spearman', datasetD_overall_sliders, \n",
    "                           datasetD_group1_sliders, datasetD_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Results Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['datasetId', 'overall_convertedR', 'overall_confidenceLowerBound', 'overall_confidenceUpperBound', 'group1_convertedR', 'group1_confidenceLowerBound', 'group1_confidenceUpperBound', 'group2_convertedR', 'group2_confidenceLowerBound', 'group2_confidenceUpperBound'], ['datasetA_ranks_pearson', 1.0, (1.0,), 1.0, 1.0, (1.0,), 1.0, 1.0, (1.0,), 1.0], ['datasetA_ranks_spearman', 1.0, (1.0,), 1.0, 1.0, (1.0,), 1.0, 1.0, (1.0,), 1.0], ['datasetA_sliders_pearson', -0.92815408104589259, (-0.95831892802560281,), -0.87752405795422161, -0.94195795200550192, (-0.97350083075272087,), -0.87524205827567558, -0.90863124738989554, (-0.95789277608377554,), -0.80740736534278179], ['datasetA_sliders_spearman', -0.98919281336798681, (-0.99381250053158132,), -0.98115659062389005, -0.99059046301835219, (-0.99576174514825067,), -0.97917530932378394, -0.98735254260592276, (-0.99429822006258683,), -0.97206444057143726], ['datasetB_ranks_pearson', 0.89552385956554437, (0.82399817378627793,), 0.93895491999852931, 0.9371219655998464, (0.86523315011858626,), 0.97125405237495188, 0.82883741492721485, (0.65518362591561641,), 0.91930087249602521], ['datasetB_ranks_spearman', 0.89552385956554437, (0.82399817378627793,), 0.93895491999852931, 0.9371219655998464, (0.86523315011858626,), 0.97125405237495188, 0.82883741492721485, (0.65518362591561641,), 0.91930087249602521], ['datasetB_sliders_pearson', -0.90005394597975064, (-0.94165979524673893,), -0.83135368454731751, -0.93840286732743128, (-0.97184974642156119,), -0.86787863047734382, -0.83980302282785602, (-0.92470949381132295,), -0.67529921771425494], ['datasetB_sliders_spearman', -0.89090538762284599, (-0.9361917320989801,), -0.81652388837882184, -0.94172337936698292, (-0.97339198966204665,), -0.87475524765549784, -0.80033028593633193, (-0.90507843100837926,), -0.60401671174434746], ['datasetC_ranks_pearson', 0.87897738401219783, (0.79733492794874516,), 0.92902933010802558, 0.90857529768532963, (0.80729568938384932,), 0.95786632579305131, 0.84059769931475048, (0.67676656567229299,), 0.92510012841455314], ['datasetC_ranks_spearman', 0.87897738401219783, (0.79733492794874516,), 0.92902933010802558, 0.90857529768532963, (0.80729568938384932,), 0.95786632579305131, 0.84059769931475048, (0.67676656567229299,), 0.92510012841455314], ['datasetC_sliders_pearson', -0.86223977747299674, (-0.91891526091296505,), -0.77068406925402733, -0.91221742771144809, (-0.95958640469893686,), -0.81458056774656629, -0.78697791649750626, (-0.89833525059926211,), -0.58059469238975481], ['datasetC_sliders_spearman', -0.87384240750223785, (-0.92593434015873488,), -0.78912464043085584, -0.91168442739867472, (-0.95933490404304411,), -0.81351254925815375, -0.82130130887234076, (-0.91556388328269733,), -0.64150050182806262], ['datasetD_ranks_pearson', 0.82435197774026903, (0.71151669663902772,), 0.89574209901193325, 0.92516685885136074, (0.8407334868846954,), 0.96567353909522646, 0.61488870010732777, (0.30648479594897737,), 0.80646268936236309], ['datasetD_ranks_spearman', 0.82435197774026903, (0.71151669663902772,), 0.89574209901193325, 0.92516685885136074, (0.8407334868846954,), 0.96567353909522646, 0.61488870010732777, (0.30648479594897737,), 0.80646268936236309], ['datasetD_sliders_pearson', -0.7686655894223221, (-0.8609639079970044,), -0.62736447708689858, -0.8954882844537817, (-0.95165636914845764,), -0.78137169851537158, -0.52639848955517865, (-0.75532246237696365,), -0.18298241904368831], ['datasetD_sliders_spearman', -0.76768054254616747, (-0.86034084357686647,), -0.6259050167298239, -0.89878606628979862, (-0.95322554844720198,), -0.78786734801231262, -0.5105277742233798, (-0.74584581555469098,), -0.16192218687209445]]\n"
     ]
    }
   ],
   "source": [
    "print(nTresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Save Results as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'nTreeStats.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-18c13f3b53fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutputDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnTresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nTreeStats.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1458\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1459\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1461\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression, memory_map)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'nTreeStats.csv'"
     ]
    }
   ],
   "source": [
    "outputDf = pd.DataFrame(nTresults)\n",
    "outputDf.to_csv('nTreeStats.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
