{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Packages Used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load data into numpy array and pandas dataframes:**\n",
    "* **datasetXX_nTreeRanks:** Ordered n-ary tree ranks for dataset XX (A, B, C, or D)\n",
    "* **datasetXX_absRanks:** Ordered absolute post-traversal ranks for dataset XX (A, B, C, or D)\n",
    "* **TODO:** At some point, update with Regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawData = np.loadtxt(fname='disagreement-mturk-raw-ids-rankings-only.csv', delimiter=',', skiprows=1, \n",
    "                     dtype=np.dtype([('version', 'i4'), ('responseId', 'S25'), \n",
    "                                     ('rDA_1', 'f4'), ('rDA_2', 'f4'), ('rDA_3', 'f4'), ('rDA_4', 'f4'), ('rDA_5', 'f4'), \n",
    "                                     ('sDA_1', 'f4'), ('sDA_2', 'f4'), ('sDA_3', 'f4'), ('sDA_4', 'f4'), ('sDA_5', 'f4'), \n",
    "                                     ('rDB_1', 'f4'), ('rDB_2', 'f4'), ('rDB_3', 'f4'), ('rDB_4', 'f4'), ('rDB_5', 'f4'), \n",
    "                                     ('sDB_1', 'f4'), ('sDB_2', 'f4'), ('sDB_3', 'f4'), ('sDB_4', 'f4'), ('sDB_5', 'f4'), \n",
    "                                     ('rDC_1', 'f4'), ('rDC_2', 'f4'), ('rDC_3', 'f4'), ('rDC_4', 'f4'), ('rDC_5', 'f4'), \n",
    "                                     ('sDC_1', 'f4'), ('sDC_2', 'f4'), ('sDC_3', 'f4'), ('sDC_4', 'f4'), ('sDC_5', 'f4'), \n",
    "                                     ('rDD_1', 'f4'), ('rDD_2', 'f4'), ('rDD_3', 'f4'), ('rDD_4', 'f4'), ('rDD_5', 'f4'), \n",
    "                                     ('sDD_1', 'f4'), ('sDD_2', 'f4'), ('sDD_3', 'f4'), ('sDD_4', 'f4'), ('sDD_5', 'f4'), \n",
    "                                     ('mTurkCode', 'S25')]))\n",
    "\n",
    "# initialize n-ary tree ranking results with headers\n",
    "nTresults = [['datasetId', \n",
    "              'table_convertedR', 'table_confidence',\n",
    "             'vis_convertedR', 'vis_confidence',\n",
    "              'overall_convertedR', 'overall_confidence']]\n",
    "\n",
    "# full data frame\n",
    "df = pd.DataFrame(rawData)\n",
    "\n",
    "# Utils for statistics and all datasets, defining 'ground truth' columns in dataframes\n",
    "overallDropCols = [50,51]\n",
    "groupDropCols = [25, 26]\n",
    "NtId = 50\n",
    "\n",
    "\n",
    "# Ground Truth Ranking Datasets\n",
    "datasetA_nTreeRanks = df.ix[df['version']==3].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_absRanks = df.ix[df['version']==4].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset A\n",
    "# Dataset A -- Table: Group 1 | Visualization: Group 2\n",
    "datasetA_overall_ranks = df.filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "\n",
    "datasetA_overall_sliders = df.filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T\n",
    "datasetA_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T\n",
    "datasetA_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset B\n",
    "# Dataset B -- Table: Group 1 | Visualization: Group 2\n",
    "datasetB_overall_ranks = df.filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "datasetB_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "datasetB_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "\n",
    "datasetB_overall_sliders = df.filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T\n",
    "datasetB_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T\n",
    "datasetB_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset C\n",
    "# Dataset C -- Table: Group 2 | Visualization: Group 1\n",
    "datasetC_overall_ranks = df.filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "datasetC_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "datasetC_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "\n",
    "datasetC_overall_sliders = df.filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T\n",
    "datasetC_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T\n",
    "datasetC_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset D\n",
    "# Dataset D -- Table: Group 2 | Visualization: Group 1\n",
    "datasetD_overall_ranks = df.filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "datasetD_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "datasetD_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "\n",
    "datasetD_overall_sliders = df.filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T\n",
    "datasetD_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T\n",
    "datasetD_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher Transformation\n",
    "* Background and Formula: https://en.wikipedia.org/wiki/Fisher_transformation\n",
    "* Implementation References: \n",
    "    1. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.925.428&rep=rep1&type=pdf\n",
    "    2. http://dept.stat.lsa.umich.edu/~kshedden/Python-Workshop/stats_calculations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fisherTransform(corr):\n",
    "    '''\n",
    "    Given 1-row matrix of correlation coefficients, computes Fisher Transform matrix of same dimensions\n",
    "    Equivalent to: F = adjustedCorr.applymap(lambda r: 0.5*np.log((1+r)/(1-r)))\n",
    "    '''\n",
    "    \n",
    "    # Treat correlation of 1 as 0.9999 to prevent undefined values\n",
    "    adjustedCorr = corr.applymap(lambda x: 0.999 if (x == 1.0) else x)\n",
    "    adjustedCorr = adjustedCorr.applymap(lambda x: -0.999 if (x == -1.0) else x)\n",
    "    \n",
    "    # Fisher transform all the correlation coefficients (equivalent to hyperbolic tangent)\n",
    "    F = np.arctanh(adjustedCorr)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgFisherTransform(F):\n",
    "    '''Given 1-row Matrix of Fisher Transform Values, returns Average Fisher Transform'''\n",
    "    return F.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisherStdErr(n):\n",
    "    '''Given sample size n, returns standard error for Fisher Transform'''\n",
    "    return (1/np.sqrt(n-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confidenceInterval(refP, critZ, stdErr):\n",
    "    '''\n",
    "    Given a reference point (generally mean of dataset) and standard error value, returns confidence interval\n",
    "    low = refP - (critZ * stdErr)\n",
    "    high = refP + (critZ * stdErr)\n",
    "    '''\n",
    "    low = refP - (critZ * stdErr)\n",
    "    high = refP + (critZ * stdErr)\n",
    "    \n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertZtoR(zVal):\n",
    "    '''\n",
    "    Given Fisher Transform z val, computes r Correlation Coefficient\n",
    "    Equivalent to return (np.exp(2*zVal)-1) / (np.exp(2*zVal)+1)\n",
    "    '''\n",
    "    return np.tanh(zVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculate Correlations and Store Results:**\n",
    "* TODO: Currently only applying n-ary tree ranking, but data is in place for absolute ranking also (indices for n-ary tree are hard-coded currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeStats(df, dropCols, gtId, statsMethod):\n",
    "    '''Helper function for buildStats. Given dataframe, indices for columns to drop, and \n",
    "    index for the ground truth ranking id, and stats method, it returns tuple of coefficients'''\n",
    "\n",
    "    # all correlations\n",
    "    corr = df.corr(method=statsMethod, min_periods=5)\n",
    "    # correlations with n-ary tree ranking\n",
    "    #TODO: these indices might need to be updated if we add absolute ranking\n",
    "    nTOverall = corr[-2:-1].drop(corr.columns[dropCols],axis=1)\n",
    "    # average n-ary tree correlation\n",
    "    avgNtOverall = nTOverall.mean(axis=1)\n",
    "    avgR = avgNtOverall[gtId]\n",
    "    \n",
    "    # average F-transform of n-ary tree metric\n",
    "    fTransform = fisherTransform(nTOverall)\n",
    "    avgFvec = avgFisherTransform(fTransform)\n",
    "    avgF = avgFvec[gtId]\n",
    "    \n",
    "    # sample size (n is number of columns, which is sample size)\n",
    "    m, n = corr.shape\n",
    "    \n",
    "    # stdErr on fisher transform\n",
    "    fStdErr = fisherStdErr(n)\n",
    "    \n",
    "    # use Z criterion of 1.96 for 95% confidence interval\n",
    "    critZ = 1.96\n",
    "    \n",
    "    # confidence interval\n",
    "    fLow, fHigh = confidenceInterval(avgF, critZ, fStdErr)\n",
    "    rLow = convertZtoR(fLow)\n",
    "    rHigh = convertZtoR(fHigh)\n",
    "    \n",
    "    # converted (transformed) average correlation coeff\n",
    "    convAvgRvec = convertZtoR(avgFvec)\n",
    "    convR = convAvgRvec[gtId]\n",
    "    \n",
    "    return convR, (rLow, rHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStats(dataId, tableGroup, visGroup, overall, statsMethod):\n",
    "    '''Given a dataset label, overall data set and dataset for each group, returns list of results for pearson method'''\n",
    "    \n",
    "    #initialize empty list of stats\n",
    "    stats=[dataId]\n",
    "    \n",
    "    # group 1 data\n",
    "    tableGroupR, tableGroupConf = computeStats(tableGroup, groupDropCols, NtId, statsMethod)\n",
    "    stats.append(tableGroupR)\n",
    "    stats.append(tableGroupConf)\n",
    "    \n",
    "    # group 2 data\n",
    "    visGroupR, visGroupConf = computeStats(visGroup, groupDropCols, NtId, statsMethod)\n",
    "    stats.append(visGroupR)\n",
    "    stats.append(visGroupConf)\n",
    "        \n",
    "    # overall data\n",
    "    overallR, overallConf = computeStats(overall, overallDropCols, NtId, statsMethod)\n",
    "    stats.append(overallR)\n",
    "    stats.append(overallConf)\n",
    "    \n",
    "    \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rankings Statistics:\n",
    "* Computed using Pearson's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset A -- Table: Group 1 | Visualization: Group 2\n",
    "aRanksPearson = buildStats('datasetA_ranks_pearson', datasetA_group1_ranks, datasetA_group2_ranks, \n",
    "                           datasetA_overall_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "\n",
    "# Dataset B -- Table: Group 1 | Visualization: Group 2\n",
    "bRanksPearson = buildStats('datasetB_ranks_pearson', datasetB_group1_ranks, datasetB_group2_ranks,\n",
    "                           datasetB_overall_ranks, 'pearson')\n",
    "nTresults.append(bRanksPearson)\n",
    "\n",
    "# Dataset C -- Table: Group 2 | Visualization: Group 1\n",
    "cRanksPearson = buildStats('datasetC_ranks_pearson', datasetC_group2_ranks, datasetC_group1_ranks,\n",
    "                           datasetC_overall_ranks, 'pearson')\n",
    "nTresults.append(cRanksPearson)\n",
    "\n",
    "# Dataset D -- Table: Group 2 | Visualization: Group 1\n",
    "dRanksPearson = buildStats('datasetD_ranks_pearson', datasetD_group2_ranks, datasetD_group1_ranks, \n",
    "                           datasetD_overall_ranks, 'pearson')\n",
    "nTresults.append(dRanksPearson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sliders Statistics:\n",
    "* Computed using Spearman's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset A -- Table: Group 1 | Visualization: Group 2\n",
    "aSlidersSpearman = buildStats('datasetA_sliders_spearman', datasetA_group1_sliders, datasetA_group2_sliders, \n",
    "                           datasetA_overall_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n",
    "\n",
    "# Dataset B -- Table: Group 1 | Visualization: Group 2\n",
    "bSlidersSpearman = buildStats('datasetB_sliders_spearman', datasetB_group1_sliders, datasetB_group2_sliders,\n",
    "                           datasetB_overall_sliders, 'spearman')\n",
    "nTresults.append(bSlidersSpearman)\n",
    "\n",
    "# Dataset C -- Table: Group 2 | Visualization: Group 1\n",
    "cSlidersSpearman = buildStats('datasetC_sliders_spearman', datasetC_group2_sliders, datasetC_group1_sliders,\n",
    "                           datasetC_overall_sliders, 'spearman')\n",
    "nTresults.append(cSlidersSpearman)\n",
    "\n",
    "# Dataset D -- Table: Group 2 | Visualization: Group 1\n",
    "dSlidersSpearman = buildStats('datasetD_sliders_spearman', datasetD_group2_sliders, datasetD_group1_sliders, \n",
    "                           datasetD_overall_sliders, 'spearman')\n",
    "nTresults.append(dSlidersSpearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Results Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['datasetId', 'table_convertedR', 'table_confidence', 'vis_convertedR', 'vis_confidence', 'overall_convertedR', 'overall_confidence'], ['datasetA_ranks_pearson', 0.9650130192345473, (0.92375712984218383, 0.98412904760714881), 0.95609512054916646, (0.90483272722154451, 0.98003416203450611), 0.96080184431832916, (0.93237184525277605, 0.97741989710516008)], ['datasetB_ranks_pearson', 0.9371219655998464, (0.86523315011858626, 0.97125405237495188), 0.82883741492721485, (0.65518362591561641, 0.91930087249602521), 0.89552385956554437, (0.82399817378627793, 0.93895491999852931)], ['datasetC_ranks_pearson', 0.84059769931475048, (0.67676656567229299, 0.92510012841455314), 0.90857529768532963, (0.80729568938384932, 0.95786632579305131), 0.87897738401219783, (0.79733492794874516, 0.92902933010802558)], ['datasetD_ranks_pearson', 0.61488870010732777, (0.30648479594897737, 0.80646268936236309), 0.92516685885136074, (0.8407334868846954, 0.96567353909522646), 0.82435197774026903, (0.71151669663902772, 0.89574209901193325)], ['datasetA_sliders_spearman', -0.97652707042542408, (-0.98938608404861361, -0.9484924125738774), -0.96787110131330101, (-0.98543711677132362, -0.92986511220693757), -0.97280714866207429, (-0.98437610918403273, -0.95287520047382579)], ['datasetB_sliders_spearman', -0.94172337936698292, (-0.97339198966204665, -0.87475524765549784), -0.80033028593633193, (-0.90507843100837926, -0.60401671174434746), -0.89090538762284599, (-0.9361917320989801, -0.81652388837882184)], ['datasetC_sliders_spearman', -0.80573223562537921, (-0.90779162492191379, -0.61358986481316635), -0.91168442739867472, (-0.95933490404304411, -0.81351254925815375), -0.868287229715899, (-0.92257818653878776, -0.78027645513506383)], ['datasetD_sliders_spearman', -0.5105277742233798, (-0.74584581555469098, -0.16192218687209445), -0.89878606628979862, (-0.95322554844720198, -0.78786734801231262), -0.76768054254616747, (-0.86034084357686647, -0.6259050167298239)]]\n"
     ]
    }
   ],
   "source": [
    "print(nTresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Save Results as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputDf = pd.DataFrame(nTresults)\n",
    "outputDf.to_csv('nTreeStats.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
