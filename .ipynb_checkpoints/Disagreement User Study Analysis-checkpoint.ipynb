{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Packages Used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load data into numpy array and pandas dataframes:**\n",
    "* **datasetXX_nTreeRanks:** Ordered n-ary tree ranks for dataset XX (A, B, C, or D)\n",
    "* **datasetXX_absRanks:** Ordered absolute post-traversal ranks for dataset XX (A, B, C, or D)\n",
    "* **TODO:** At some point, update with Regex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawData = np.loadtxt(fname='disagreement-mturk-raw-ids-rankings-only.csv', delimiter=',', skiprows=1, \n",
    "                     dtype=np.dtype([('version', 'i4'), ('responseId', 'S25'), \n",
    "                                     ('rDA_1', 'f4'), ('rDA_2', 'f4'), ('rDA_3', 'f4'), ('rDA_4', 'f4'), ('rDA_5', 'f4'), \n",
    "                                     ('sDA_1', 'f4'), ('sDA_2', 'f4'), ('sDA_3', 'f4'), ('sDA_4', 'f4'), ('sDA_5', 'f4'), \n",
    "                                     ('rDB_1', 'f4'), ('rDB_2', 'f4'), ('rDB_3', 'f4'), ('rDB_4', 'f4'), ('rDB_5', 'f4'), \n",
    "                                     ('sDB_1', 'f4'), ('sDB_2', 'f4'), ('sDB_3', 'f4'), ('sDB_4', 'f4'), ('sDB_5', 'f4'), \n",
    "                                     ('rDC_1', 'f4'), ('rDC_2', 'f4'), ('rDC_3', 'f4'), ('rDC_4', 'f4'), ('rDC_5', 'f4'), \n",
    "                                     ('sDC_1', 'f4'), ('sDC_2', 'f4'), ('sDC_3', 'f4'), ('sDC_4', 'f4'), ('sDC_5', 'f4'), \n",
    "                                     ('rDD_1', 'f4'), ('rDD_2', 'f4'), ('rDD_3', 'f4'), ('rDD_4', 'f4'), ('rDD_5', 'f4'), \n",
    "                                     ('sDD_1', 'f4'), ('sDD_2', 'f4'), ('sDD_3', 'f4'), ('sDD_4', 'f4'), ('sDD_5', 'f4'), \n",
    "                                     ('mTurkCode', 'S25')]))\n",
    "\n",
    "# initialize n-ary tree ranking results with headers\n",
    "nTresults = [['datasetId', 'overall_convertedR', 'overall_confidence',\n",
    "             'group1_convertedR', 'group1_confidence',\n",
    "             'group2_convertedR', 'group2_confidence']]\n",
    "\n",
    "# full data frame\n",
    "df = pd.DataFrame(rawData)\n",
    "\n",
    "# Utils for statistics and all datasets, defining 'ground truth' columns in dataframes\n",
    "overallDropCols = [50,51]\n",
    "groupDropCols = [25, 26]\n",
    "NtId = 50\n",
    "\n",
    "\n",
    "# Ground Truth Ranking Datasets\n",
    "datasetA_nTreeRanks = df.ix[df['version']==3].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_absRanks = df.ix[df['version']==4].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset A\n",
    "datasetA_overall_ranks = df.filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "datasetA_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5']).T\n",
    "\n",
    "datasetA_overall_sliders = df.filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T\n",
    "datasetA_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T\n",
    "datasetA_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDA_1', 'sDA_2', 'sDA_3', 'sDA_4', 'sDA_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset B\n",
    "datasetB_overall_ranks = df.filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "datasetB_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "datasetB_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDB_1', 'rDB_2', 'rDB_3', 'rDB_4', 'rDB_5']).T\n",
    "\n",
    "datasetB_overall_sliders = df.filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T\n",
    "datasetB_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T\n",
    "datasetB_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDB_1', 'sDB_2', 'sDB_3', 'sDB_4', 'sDB_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset C\n",
    "datasetC_overall_ranks = df.filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "datasetC_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "datasetC_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDC_1', 'rDC_2', 'rDC_3', 'rDC_4', 'rDC_5']).T\n",
    "\n",
    "datasetC_overall_sliders = df.filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T\n",
    "datasetC_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T\n",
    "datasetC_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDC_1', 'sDC_2', 'sDC_3', 'sDC_4', 'sDC_5']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset D\n",
    "datasetD_overall_ranks = df.filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "datasetD_group1_ranks = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "datasetD_group2_ranks = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['rDD_1', 'rDD_2', 'rDD_3', 'rDD_4', 'rDD_5']).T\n",
    "\n",
    "datasetD_overall_sliders = df.filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T\n",
    "datasetD_group1_sliders = df.ix[(df['version']==1) | (df['version']==3) | (df['version']==4)].filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T\n",
    "datasetD_group2_sliders = df.ix[(df['version']==2) | (df['version']==3) | (df['version']==4)].filter(['sDD_1', 'sDD_2', 'sDD_3', 'sDD_4', 'sDD_5']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher Transformation\n",
    "* Background and Formula: https://en.wikipedia.org/wiki/Fisher_transformation\n",
    "* Implementation References: \n",
    "    1. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.925.428&rep=rep1&type=pdf\n",
    "    2. http://dept.stat.lsa.umich.edu/~kshedden/Python-Workshop/stats_calculations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fisherTransform(corr):\n",
    "    '''Given 1-row matrix of correlation coefficients, computes Fisher Transform matrix of same dimensions'''\n",
    "    \n",
    "    # Treat correlation of 1 as 0.9999 to prevent undefined values\n",
    "    adjustedCorr = corr.applymap(lambda x: 0.999 if (x == 1.0) else x)\n",
    "    adjustedCorr = corr.applymap(lambda x: -0.999 if (x == -1.0) else x)\n",
    "    adjustedCorr = corr.applymap(lambda x: 0.001 if (x == 0.0) else x)\n",
    "    \n",
    "    # Fisher transform all the correlation coefficients (equivalent to hyperbolic tangent)\n",
    "    F = np.arctanh(adjustedCorr)\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgFisherTransform(F):\n",
    "    '''Given 1-row Matrix of Fisher Transform Values, returns Average Fisher Transform'''\n",
    "    return F.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fisherStdErr(n):\n",
    "    '''Given sample size n, returns standard error for Fisher Transform'''\n",
    "    return (1/np.sqrt(n-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confidenceInterval(refP, critZ, stdErr):\n",
    "    '''\n",
    "    Given a reference point (generally mean of dataset) and standard error value, returns confidence interval\n",
    "    low = refP - (critZ * stdErr)\n",
    "    high = refP + (critZ * stdErr)\n",
    "    '''\n",
    "    low = refP - (critZ * stdErr)\n",
    "    high = refP + (critZ * stdErr)\n",
    "    \n",
    "    return low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertZtoR(zVal):\n",
    "    '''Given Fisher Transform z val, computes r Correlation Coefficient'''\n",
    "    return np.tanh(zVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculate Correlations and Store Results:**\n",
    "* TODO: Currently only applying n-ary tree ranking, but data is in place for absolute ranking also (indices for n-ary tree are hard-coded currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeStats(df, dropCols, gtId, statsMethod):\n",
    "    '''Helper function for buildStats. Given dataframe, indices for columns to drop, and \n",
    "    index for the ground truth ranking id, and stats method, it returns tuple of coefficients'''\n",
    "\n",
    "    # all correlations\n",
    "    corr = df.corr(method=statsMethod, min_periods=5)\n",
    "    # correlations with n-ary tree ranking\n",
    "    #TODO: these indices might need to be updated if we add absolute ranking\n",
    "    nTOverall = corr[-2:-1].drop(corr.columns[dropCols],axis=1)\n",
    "    # average n-ary tree correlation\n",
    "    avgNtOverall = nTOverall.mean(axis=1)\n",
    "    avgR = avgNtOverall[gtId]\n",
    "    \n",
    "    # average F-transform of n-ary tree metric\n",
    "    fTransform = fisherTransform(nTOverall)\n",
    "    avgFvec = avgFisherTransform(fTransform)\n",
    "    avgF = avgFvec[gtId]\n",
    "    \n",
    "    # sample size (n is number of columns, which is sample size)\n",
    "    m, n = corr.shape\n",
    "    \n",
    "    # stdErr on fisher transform\n",
    "    fStdErr = fisherStdErr(n)\n",
    "    \n",
    "    # use Z criterion of 1.96 for 95% confidence interval\n",
    "    critZ = 1.96\n",
    "    \n",
    "    # confidence interval\n",
    "    fLow, fHigh = confidenceInterval(avgF, critZ, fStdErr)\n",
    "    rLow = convertZtoR(fLow)\n",
    "    rHigh = convertZtoR(fHigh)\n",
    "    \n",
    "    # converted (transformed) average correlation coeff\n",
    "    convAvgRvec = convertZtoR(avgFvec)\n",
    "    convR = convAvgRvec[gtId]\n",
    "    \n",
    "    return convR, (rLow, rHigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildStats(dataId, overall, group1, group2, statsMethod):\n",
    "    '''Given a dataset label, overall data set and dataset for each group, returns list of results for pearson method'''\n",
    "    \n",
    "    #initialize empty list of stats\n",
    "    stats=[dataId]\n",
    "    \n",
    "    # overall data\n",
    "    overallR, overallConf = computeStats(overall, overallDropCols, NtId, statsMethod)\n",
    "    stats.append(overallR)\n",
    "    stats.append(overallConf)\n",
    "    \n",
    "    # group 1 data\n",
    "    group1R, group1Conf = computeStats(group1, groupDropCols, NtId, statsMethod)\n",
    "    stats.append(group1R)\n",
    "    stats.append(group1Conf)\n",
    "    \n",
    "    # group 2 data\n",
    "    group2R, group2Conf = computeStats(group2, groupDropCols, NtId, statsMethod)\n",
    "    stats.append(group2R)\n",
    "    stats.append(group2Conf)\n",
    "    \n",
    "    \n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:10: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow:\n",
      "inf\n",
      "fhigh:\n",
      "inf\n",
      "flow:\n",
      "inf\n",
      "fhigh:\n",
      "inf\n",
      "flow:\n",
      "inf\n",
      "fhigh:\n",
      "inf\n",
      "flow:\n",
      "inf\n",
      "fhigh:\n",
      "inf\n",
      "flow:\n",
      "inf\n",
      "fhigh:\n",
      "inf\n",
      "flow:\n",
      "inf\n",
      "fhigh:\n",
      "inf\n",
      "flow:\n",
      "-1.92489728907\n",
      "fhigh:\n",
      "-1.36489728907\n",
      "flow:\n",
      "-2.15522546636\n",
      "fhigh:\n",
      "-1.35505881705\n",
      "flow:\n",
      "-1.9197023721\n",
      "fhigh:\n",
      "-1.11953572279\n",
      "flow:\n",
      "-inf\n",
      "fhigh:\n",
      "-inf\n",
      "flow:\n",
      "-inf\n",
      "fhigh:\n",
      "-inf\n",
      "flow:\n",
      "-inf\n",
      "fhigh:\n",
      "-inf\n"
     ]
    }
   ],
   "source": [
    "# Dataset A Stats\n",
    "\n",
    "# Dataset A Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetA_ranks_pearson', datasetA_overall_ranks, \n",
    "                           datasetA_group1_ranks, datasetA_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetA_ranks_spearman', datasetA_overall_ranks, \n",
    "                           datasetA_group1_ranks, datasetA_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset A Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetA_sliders_pearson', datasetA_overall_sliders, \n",
    "                           datasetA_group1_sliders, datasetA_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetA_sliders_spearman', datasetA_overall_sliders, \n",
    "                           datasetA_group1_sliders, datasetA_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow:\n",
      "1.16914589911\n",
      "fhigh:\n",
      "1.72914589911\n",
      "flow:\n",
      "1.31379754513\n",
      "fhigh:\n",
      "2.11396419444\n",
      "flow:\n",
      "0.784327603783\n",
      "fhigh:\n",
      "1.58449425309\n",
      "flow:\n",
      "1.16914589911\n",
      "fhigh:\n",
      "1.72914589911\n",
      "flow:\n",
      "1.31379754513\n",
      "fhigh:\n",
      "2.11396419444\n",
      "flow:\n",
      "0.784327603783\n",
      "fhigh:\n",
      "1.58449425309\n",
      "flow:\n",
      "-1.75250348837\n",
      "fhigh:\n",
      "-1.19250348837\n",
      "flow:\n",
      "-2.12458548805\n",
      "fhigh:\n",
      "-1.32441883874\n",
      "flow:\n",
      "-1.620588138\n",
      "fhigh:\n",
      "-0.820421488692\n",
      "flow:\n",
      "-1.70629776261\n",
      "fhigh:\n",
      "-1.14629776261\n",
      "flow:\n",
      "-2.15314842614\n",
      "fhigh:\n",
      "-1.35298177683\n",
      "flow:\n",
      "-1.4996137484\n",
      "fhigh:\n",
      "-0.699447099088\n"
     ]
    }
   ],
   "source": [
    "# Dataset B Stats\n",
    "\n",
    "# Dataset B Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetB_ranks_pearson', datasetB_overall_ranks, \n",
    "                           datasetB_group1_ranks, datasetB_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetB_ranks_spearman', datasetB_overall_ranks, \n",
    "                           datasetB_group1_ranks, datasetB_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset B Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetB_sliders_pearson', datasetB_overall_sliders, \n",
    "                           datasetB_group1_sliders, datasetB_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetB_sliders_spearman', datasetB_overall_sliders, \n",
    "                           datasetB_group1_sliders, datasetB_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:10: RuntimeWarning: divide by zero encountered in arctanh\n"
     ]
    }
   ],
   "source": [
    "# Dataset C Stats\n",
    "\n",
    "# Dataset C Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetC_ranks_pearson', datasetC_overall_ranks, \n",
    "                           datasetC_group1_ranks, datasetC_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetC_ranks_spearman', datasetC_overall_ranks, \n",
    "                           datasetC_group1_ranks, datasetC_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset C Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetC_sliders_pearson', datasetC_overall_sliders, \n",
    "                           datasetC_group1_sliders, datasetC_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetC_sliders_spearman', datasetC_overall_sliders, \n",
    "                           datasetC_group1_sliders, datasetC_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset D Stats\n",
    "\n",
    "# Dataset D Ranks \n",
    "# Pearson Stats\n",
    "aRanksPearson = buildStats('datasetD_ranks_pearson', datasetD_overall_ranks, \n",
    "                           datasetD_group1_ranks, datasetD_group2_ranks, 'pearson')\n",
    "nTresults.append(aRanksPearson)\n",
    "# Spearman Stats\n",
    "aRanksSpearman = buildStats('datasetD_ranks_spearman', datasetD_overall_ranks, \n",
    "                           datasetD_group1_ranks, datasetD_group2_ranks, 'spearman')\n",
    "nTresults.append(aRanksSpearman)\n",
    "\n",
    "# Dataset D Sliders\n",
    "# Pearson Stats\n",
    "aSlidersPearson = buildStats('datasetD_sliders_pearson', datasetD_overall_sliders, \n",
    "                           datasetD_group1_sliders, datasetD_group2_sliders, 'pearson')\n",
    "nTresults.append(aSlidersPearson)\n",
    "# Spearman Stats\n",
    "aSlidersSpearman = buildStats('datasetD_sliders_spearman', datasetD_overall_sliders, \n",
    "                           datasetD_group1_sliders, datasetD_group2_sliders, 'spearman')\n",
    "nTresults.append(aSlidersSpearman)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Results Table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['datasetId', 'overall_convertedR', 'overall_confidence', 'group1_convertedR', 'group1_confidence', 'group2_convertedR', 'group2_confidence'], ['datasetA_ranks_pearson', 1.0, ((1.0,), 1.0), 1.0, ((1.0,), 1.0), 1.0, ((1.0,), 1.0)], ['datasetA_ranks_spearman', 1.0, ((1.0,), 1.0), 1.0, ((1.0,), 1.0), 1.0, ((1.0,), 1.0)], ['datasetA_sliders_pearson', -0.92815408104589259, ((-0.95831892802560281,), -0.87752405795422161), -0.94195795200550192, ((-0.97350083075272087,), -0.87524205827567558), -0.90863124738989554, ((-0.95789277608377554,), -0.80740736534278179)], ['datasetA_sliders_spearman', -1.0, ((-1.0,), -1.0), -1.0, ((-1.0,), -1.0), -1.0, ((-1.0,), -1.0)], ['datasetB_ranks_pearson', 0.89552385956554437, ((0.82399817378627793,), 0.93895491999852931), 0.9371219655998464, ((0.86523315011858626,), 0.97125405237495188), 0.82883741492721485, ((0.65518362591561641,), 0.91930087249602521)], ['datasetB_ranks_spearman', 0.89552385956554437, ((0.82399817378627793,), 0.93895491999852931), 0.9371219655998464, ((0.86523315011858626,), 0.97125405237495188), 0.82883741492721485, ((0.65518362591561641,), 0.91930087249602521)], ['datasetB_sliders_pearson', -0.90005394597975064, ((-0.94165979524673893,), -0.83135368454731751), -0.93840286732743128, ((-0.97184974642156119,), -0.86787863047734382), -0.83980302282785602, ((-0.92470949381132295,), -0.67529921771425494)], ['datasetB_sliders_spearman', -0.89090538762284599, ((-0.9361917320989801,), -0.81652388837882184), -0.94172337936698292, ((-0.97339198966204665,), -0.87475524765549784), -0.80033028593633193, ((-0.90507843100837926,), -0.60401671174434746)], ['datasetC_ranks_pearson', 0.87897738401219783, ((0.79733492794874516,), 0.92902933010802558), 0.90857529768532963, ((0.80729568938384932,), 0.95786632579305131), 0.84059769931475048, ((0.67676656567229299,), 0.92510012841455314)], ['datasetC_ranks_spearman', 0.87897738401219783, ((0.79733492794874516,), 0.92902933010802558), 0.90857529768532963, ((0.80729568938384932,), 0.95786632579305131), 0.84059769931475048, ((0.67676656567229299,), 0.92510012841455314)], ['datasetC_sliders_pearson', -0.86223977747299674, ((-0.91891526091296505,), -0.77068406925402733), -0.91221742771144809, ((-0.95958640469893686,), -0.81458056774656629), -0.78697791649750626, ((-0.89833525059926211,), -0.58059469238975481)], ['datasetC_sliders_spearman', -1.0, ((-1.0,), -1.0), -0.91168442739867472, ((-0.95933490404304411,), -0.81351254925815375), -1.0, ((-1.0,), -1.0)], ['datasetD_ranks_pearson', 0.82435197774026903, ((0.71151669663902772,), 0.89574209901193325), 0.92516685885136074, ((0.8407334868846954,), 0.96567353909522646), 0.61488870010732777, ((0.30648479594897737,), 0.80646268936236309)], ['datasetD_ranks_spearman', 0.82435197774026903, ((0.71151669663902772,), 0.89574209901193325), 0.92516685885136074, ((0.8407334868846954,), 0.96567353909522646), 0.61488870010732777, ((0.30648479594897737,), 0.80646268936236309)], ['datasetD_sliders_pearson', -0.7686655894223221, ((-0.8609639079970044,), -0.62736447708689858), -0.8954882844537817, ((-0.95165636914845764,), -0.78137169851537158), -0.52639848955517865, ((-0.75532246237696365,), -0.18298241904368831)], ['datasetD_sliders_spearman', -0.76768054254616747, ((-0.86034084357686647,), -0.6259050167298239), -0.89878606628979862, ((-0.95322554844720198,), -0.78786734801231262), -0.5105277742233798, ((-0.74584581555469098,), -0.16192218687209445)]]\n"
     ]
    }
   ],
   "source": [
    "print(nTresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Save Results as CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputDf = pd.DataFrame(nTresults)\n",
    "outputDf.to_csv('nTreeStats.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
